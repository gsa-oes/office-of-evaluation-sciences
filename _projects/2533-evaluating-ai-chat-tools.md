---
title: Evaluating Generative Artificial Intelligence (GenAI) chat tools
permalink: /projects/2533-evaluating-gen-ai-chat-tools/
tags: 
 - project
share_image: /assets/img/project-images/2533.jpg
image: /assets/img/project-images/2533.jpg
image_alt_text: Artificial intelligence theme
image-credit: https://commons.wikimedia.org/wiki/File:Artificial-Intelligence.jpg
abstract: /assets/abstracts/2533-evaluation-summary.pdf
year: 2025
domain:
type: Formative evaluation
agency: General Services Administration
status: Complete
summary: Learning about U.S. General Services Administration employees’ GenAI usage and support needs
featured:
- 
---
## Summary
The use of generative artificial intelligence (GenAI) in the federal government presents opportunities to <a class="usa-link usa-link--external" href="https://www.whitehouse.gov/wp-content/uploads/2025/02/M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf">enhance efficiency, increase quality of public services, and bring the best value to taxpayers</a>. The goals of this evaluation were to understand GenAI usage, barriers to use, and training needs of U.S. General Service Administration (GSA) employees. We found that 35% of GSA employees used GSA chat (GSA’s internal GenAI tool) at least once during the first five weeks post-launch, and employee experiences and training needs differed depending on their level of use. These insights can be used to increase GenAI use and employee knowledge to accelerate AI adoption.  

## Agency priority
GSA is a leader in modernizing and streamlining technology across government, including promoting responsible AI innovation in support of the Administration’s <a class="usa-link usa-link--external" href="https://www.whitehouse.gov/wp-content/uploads/2025/02/M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf">Executive Order</a> to accelerate federal AI use. To support AI innovation and enhance government efficiency, GSA developed an internal GenAI chatbot (GSA chat) and was interested in learning about employees’ experience using chat to improve the future product.

## What we evaluated
We partnered with GSA’s Office of Information Technology, Voice of the Customer team, and Federal Acquisition Service’s Office of Strategy and Innovation to evaluate GSA’s use of GenAI tools, with particular interest in GSA chat.

This evaluation had three primary goals:
1. Understand GenAI usage, particularly GSA chat<sup>1</sup>,
2. Catalog the barriers users face to engaging with GSA chat, and 
3. Understand user interest in additional training and/or support.

We analyzed three data sources for this evaluation. First, user logs from GSA chat’s database (telemetry data) from the first five weeks post-launch (March 21-April 25, 2025) were analyzed to understand how GSA employees engaged with GSA chat (e.g., prompt writing, AI model selection). Second, data from an online survey was analyzed to assess GSA employee attitudes and perceptions of GenAI tools, including GSA chat.<sup>2</sup> Third, we conducted six semi-structured follow-up interviews with survey respondents to better understand user needs and barriers.

## What we learned
We found that GSA chat was used by 3,959 employees within its initial five weeks, representing approximately 35% of GSA employees.<sup>3</sup> Of the 281 survey respondents, those who frequently used GSA chat were more likely to participate in the survey. Key findings are described below. 

1. <b>GSA chat usage.</b> Most users only prompted GSA chat a few times, with a median of six prompts, and 82% of users used only the default AI model set by GSA chat. Only 16% of users provided feedback on GSA chat’s responses. Among survey respondents who used GSA chat, the most frequently cited benefit was efficiency and time savings, while the primary use cases reported were drafting/editing text, summarization, and research. More frequent GenAI use was associated with the belief that GSA chat would improve work productivity.
2. <b>Barriers to increasing usage.</b> The top selected barriers to increased GSA chat use were inaccurate content (33%) and poor output quality (33%). The top selected drawback was that GSA chat was not integrated into existing workflows (52%).
3. <b>Training or additional support.</b> Respondents were most interested in training and additional support on practical applications of GenAI tools (such as coding) and guidelines for GSA chat usage.

<b>Types of GSA chat users:</b> To gain a clearer understanding of engagement with GSA chat, we categorized survey respondents based on their frequency of use. We then examined variations in their survey responses. Two overarching groups were created: those who had never used GSA chat (“Never” users) and those who had used GSA chat (GSA chat users).

- <b>“Never” users.</b> Although telemetry data indicated about 65% of GSA employees never used GSA chat during the evaluation period, only 26% (n=72) of survey respondents reported not using GSA chat. We identified two distinct types of “Never” users in the survey:
1. GenAI-avoidant users, who did not try any GenAI tools during the study period (n=33).
2. GSA chat-avoidant users, who did not try GSA chat though used other AI tools (n=39). 

There were key differences in perceived benefits, barriers, drawbacks, and training interests among the two “Never” user groups (Table 1).

Table 1. The most frequently selected benefits, barriers, drawbacks, and training interests among two categories of “Never” user groups

| Column 1 | Column 2 | Column 3 | Column 4 |
| -------- | -------- | -------- | -------- |
| Row 1, Cell 1 | Row 1, Cell 2 | Row 1, Cell 3 | Row 1, Cell 4 |
| Row 2, Cell 1 | Row 2, Cell 2 | Row 2, Cell 3 | Row 2, Cell 4 |
| Row 3, Cell 1 | Row 3, Cell 2 | Row 3, Cell 3 | Row 3, Cell 4 |
